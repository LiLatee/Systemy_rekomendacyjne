{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>n_clicks</th>\n",
       "      <th>views</th>\n",
       "      <th>clicks_views_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5003</td>\n",
       "      <td>6.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  n_clicks  views  clicks_views_ratio\n",
       "0     5001       3.0     99            0.030303\n",
       "1     5002       6.0     68            0.088235\n",
       "2     5003       6.0     90            0.066667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_metadata = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\item_metadata_all.csv',\n",
    "                       sep=',',\n",
    "                        usecols=[\"item_id\",\"n_clicks\",\"views\",\"clicks_views_ratio\"])\n",
    "item_metadata[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\additional_resources\\\\2019-master\\data\\\\train.csv',\n",
    "                       sep=',',\n",
    "#                         skiprows=range(1,3000000),\n",
    "#                       nrows=1000000,\n",
    "                      index_col=0)\n",
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[train_set['action_type'] == 'clickout item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(s):\n",
    "    \"\"\"Convert pipe separated string to array.\"\"\"\n",
    "\n",
    "    if isinstance(s, str):\n",
    "        out = s.split(\"|\")\n",
    "    elif math.isnan(s):\n",
    "        out = []\n",
    "    else:\n",
    "        raise ValueError(\"Value must be either string of nan\")\n",
    "    return out\n",
    "\n",
    "def explode_impressions_and_prices(df_in):\n",
    "    \"\"\"Explode column col_expl of array type into multiple rows.\"\"\"\n",
    "\n",
    "    df = df_in.copy()\n",
    "    df.loc[:, 'impressions'] = df['impressions'].apply(string_to_array)  # zamienia 1|2|3 na [1,2,3]\n",
    "    df.loc[:, 'prices'] = df['prices'].apply(string_to_array)  # zamienia 1|2|3 na [1,2,3]\n",
    "\n",
    "    df = df.sort_values(by=['session_id'])\n",
    "    df['number_of_impressions'] = df['impressions'].apply(len)\n",
    "    \n",
    "    df_out = pd.DataFrame(\n",
    "        {col: np.repeat(df[col].values,\n",
    "                        df['impressions'].str.len())\n",
    "         for col in df.columns.drop('impressions')}\n",
    "    )\n",
    "    \n",
    "\n",
    "    df_out.loc[:, 'impressions'] = np.concatenate(df['impressions'].values)\n",
    "    df_out.loc[:, 'impressions'] = df_out['impressions'].apply(int)\n",
    "    \n",
    "    df_out.loc[:, 'prices'] = np.concatenate(df['prices'].values)\n",
    "    df_out.loc[:, 'prices'] = df_out['prices'].apply(int)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_set = explode_impressions_and_prices(train_set)\n",
    "print(time.time() - start)\n",
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[['reference', 'impressions']]\n",
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_set = train_set.merge(item_metadata,\n",
    "                           left_on='impressions',\n",
    "                           right_on='item_id',\n",
    "                           how='left')\n",
    "train_set = train_set.drop(['impressions'], axis=1)\n",
    "train_set = train_set.fillna(0)\n",
    "# train_set.iloc[:,4:] = train_set.iloc[:,4:].astype('int8')\n",
    "print(time.time() - start)\n",
    "train_set[\"reference\"] = train_set[\"reference\"].astype(int)\n",
    "train_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.iloc[:,:2] = train_set.iloc[:,:2].astype(int)\n",
    "train_set['clicked'] = np.where(train_set['reference'] == train_set['item_id'], 1, 0)\n",
    "train_set = train_set.drop(columns=['reference','item_id'])\n",
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAUKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['clicked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = out.dropna()\n",
    "X = train_set.iloc[:, :-1]\n",
    "y = train_set['clicked'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "# X_train = normalize(X_train, norm='l2')\n",
    "X_test = sc.transform(X_test)\n",
    "# X_test = normalize(X_test, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "cc = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = cc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import ADASYN\n",
    "# adasyn = ADASYN(random_state=1, n_jobs=-1)\n",
    "# X_train, y_train = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(n_jobs=-1) #, class_weight={1.0:0.4, 0.0:0.6}\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "# THRESHOLD = 0.7\n",
    "# y_pred = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\additional_resources\\\\2019-master\\data\\\\test.csv',\n",
    "                       sep=',',\n",
    "#                        nrows=1472418\n",
    "                      skiprows=range(1,1472419)\n",
    "                      )\n",
    "mask = test_set[\"reference\"].isnull() & (test_set[\"action_type\"] == \"clickout item\")\n",
    "test_set = test_set[mask]\n",
    "test_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set[1676230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = explode_impressions_and_prices(test_set)\n",
    "test_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[['impressions', 'number_of_impressions', 'step', 'user_id','session_id', 'timestamp']]\n",
    "test_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.merge(item_metadata,\n",
    "                           left_on='impressions',\n",
    "                           right_on='item_id',\n",
    "                           how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.drop(['impressions'], axis=1)\n",
    "test_set = test_set.fillna(0)\n",
    "test_set.iloc[:,8:] = test_set.iloc[:,8:].astype('int8')\n",
    "test_set.iloc[:,6:7] = test_set.iloc[:,6:7].astype('int8')\n",
    "\n",
    "test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids = test_set[['item_id','number_of_impressions', 'step', 'user_id','session_id','timestamp']]\n",
    "test_set = test_set.drop(columns=['item_id', 'number_of_impressions', 'step', 'user_id','session_id','timestamp'])\n",
    "test_set[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(test_set.values)\n",
    "X_test = normalize(X_test, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results[['item_id', 'number_of_impressions', 'step', 'user_id','session_id','timestamp']] = item_ids\n",
    "df_results = df_results[['item_id', 'number_of_impressions', 'step', 'user_id','session_id', 'timestamp', 0, 1]]\n",
    "df_results['item_id'] = df_results['item_id'].astype(int)\n",
    "df_results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddd(df):\n",
    "    return df[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_results.groupby(['item_id','number_of_impressions','step','user_id','session_id','timestamp']).apply(ddd)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['user_id','session_id','timestamp',0], ascending=[True, True, True, False])\n",
    "df = df.drop(columns=['number_of_impressions'])\n",
    "df = df[['user_id', 'session_id','timestamp','step',0]]\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={'index':'item_id'})\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_concat(df, gr_cols, col_concat):\n",
    "    \"\"\"Concatenate multiple rows into one.\"\"\"\n",
    "\n",
    "    df_out = (\n",
    "        df\n",
    "        .groupby(gr_cols)[col_concat]\n",
    "        .apply(lambda x: ' '.join(x))\n",
    "        .to_frame()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df['item_id'].astype(str)\n",
    "df = group_concat(df, [\"user_id\", \"session_id\", \"timestamp\", \"step\"], 'item_id')\n",
    "df = df.rename(columns={'item_id':'item_recommendations'})\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\submission_ML2.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\submission_ML1.csv',\n",
    "                       sep=',')\n",
    "df1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\submission_ML2.csv',\n",
    "                       sep=',')\n",
    "df2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, df2])\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\submission_ML.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
