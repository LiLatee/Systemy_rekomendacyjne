{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dummies = pd.read_csv(\"D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\out_dummies.csv\", \n",
    "                          sep=',', \n",
    "                           nrows=2000000\n",
    "#                          skiprows=range(1, 10)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metadata_separated_properties = pd.read_csv('D:\\\\Dokumenty\\\\Systemy_rekomendacyjne\\\\data\\\\item_metadata_separated_properties.csv',\n",
    "                       sep=',')\n",
    "item_metadata_separated_properties[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_merged = out_dummies.merge(item_metadata_separated_properties,\n",
    "                              left_on='impressions',\n",
    "                              right_on='item_id',\n",
    "                              how='left')\n",
    "out_merged = out_merged.drop(['item_id'], axis=1)\n",
    "out_merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_merged['sum_of_properties'] = out_merged.iloc[:, 22:].sum(axis=1)\n",
    "out_merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = out_merged.rename(columns={'reference':'first_on_list'})\n",
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype({'first_on_list' : str, 'impressions' : str})\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['first_on_list'] = np.where(train['first_on_list'] == train['impressions'], 1, 0)\n",
    "# train.loc[train['first_on_list'] == train['impressions'], 'first_on_list'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['impressions'], axis=1)\n",
    "train = train.astype('float')\n",
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "X = train.iloc[:, 1:]\n",
    "y = train['first_on_list'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_train = normalize(X_train, norm='l2')\n",
    "X_test = sc.transform(X_test)\n",
    "X_test = normalize(X_test, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=1, n_jobs=-1)\n",
    "X_train, y_train = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(n_jobs=-1)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "\n",
    "print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
